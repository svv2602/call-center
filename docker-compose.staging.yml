# Staging environment â€” full production-like stack with isolated ports.
#
# Usage:
#   docker compose -f docker-compose.staging.yml --env-file .env.staging up -d
#   ./scripts/smoke_test_staging.sh
#   docker compose -f docker-compose.staging.yml down -v

services:
  call-processor:
    build: .
    ports:
      - "19092:9092"   # AudioSocket (staging offset +10000)
      - "18080:8080"   # API / Prometheus metrics
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/secrets/gcp-key.json
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-sk-ant-staging-placeholder}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-sonnet-4-5-20250929}
      - STORE_API_URL=http://store-api:3000/api/v1
      - STORE_API_KEY=${STORE_API_KEY:-test-store-api-key}
      - DATABASE_URL=postgresql+asyncpg://callcenter:${POSTGRES_PASSWORD:-staging_pass}@postgres:5432/callcenter_staging
      - REDIS_URL=redis://redis:6379/0
      - ARI_URL=${ARI_URL:-http://localhost:8088/ari}
      - ARI_USER=${ARI_USER:-}
      - ARI_PASSWORD=${ARI_PASSWORD:-}
      - CELERY_BROKER_URL=redis://redis:6379/1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=json
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      store-api:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health')"]
      interval: 15s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 4G

  store-api:
    build: ./mock-store-api
    ports:
      - "13002:3000"
    environment:
      - STORE_API_KEY=${STORE_API_KEY:-test-store-api-key}
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:3000/api/v1/health')"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M

  postgres:
    image: pgvector/pgvector:pg16
    ports:
      - "15432:5432"
    volumes:
      - pgdata_staging:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: callcenter_staging
      POSTGRES_USER: callcenter
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-staging_pass}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U callcenter -d callcenter_staging"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2G

  redis:
    image: redis:7-alpine
    ports:
      - "16379:6379"
    volumes:
      - redisdata_staging:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

  celery-worker:
    build: .
    command: celery -A src.tasks.celery_app worker -l info -Q quality,stats -c 2
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-sk-ant-staging-placeholder}
      - DATABASE_URL=postgresql+asyncpg://callcenter:${POSTGRES_PASSWORD:-staging_pass}@postgres:5432/callcenter_staging
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - QUALITY_LLM_MODEL=claude-haiku-4-5-20251001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G

  celery-beat:
    build: .
    command: celery -A src.tasks.celery_app beat -l info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - DATABASE_URL=postgresql+asyncpg://callcenter:${POSTGRES_PASSWORD:-staging_pass}@postgres:5432/callcenter_staging
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

  prometheus:
    image: prom/prometheus:v2.53.0
    ports:
      - "19090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_staging:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=7d"
    depends_on:
      - call-processor
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

  grafana:
    image: grafana/grafana:11.1.0
    ports:
      - "13000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-staging_admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_INSTALL_PLUGINS: grafana-postgresql-datasource
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-staging_pass}
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_staging:/var/lib/grafana
    depends_on:
      - prometheus
      - postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

  alertmanager:
    image: prom/alertmanager:v0.27.0
    ports:
      - "19093:9093"
    volumes:
      - ./alertmanager/config.yml:/etc/alertmanager/alertmanager.yml:ro
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 128M

volumes:
  pgdata_staging:
  redisdata_staging:
  prometheus_staging:
  grafana_staging:
